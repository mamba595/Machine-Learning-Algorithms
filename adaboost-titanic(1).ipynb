{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:08.442220Z","iopub.execute_input":"2025-07-27T14:45:08.442511Z","iopub.status.idle":"2025-07-27T14:45:10.673537Z","shell.execute_reply.started":"2025-07-27T14:45:08.442487Z","shell.execute_reply":"2025-07-27T14:45:10.672857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# read the data\ntitanic = pd.read_csv('/kaggle/input/titanic/train.csv')\n\n# get a glimpse over the data\ntitanic.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:10.674503Z","iopub.execute_input":"2025-07-27T14:45:10.674881Z","iopub.status.idle":"2025-07-27T14:45:10.721568Z","shell.execute_reply.started":"2025-07-27T14:45:10.674859Z","shell.execute_reply":"2025-07-27T14:45:10.720763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# reviewing the data, I find out that all the numerical columns \n# are complete, except for the Age column, which is normal, \n# since some people may have sneaked into the boat to immigrate to America\ntitanic.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:10.722440Z","iopub.execute_input":"2025-07-27T14:45:10.722758Z","iopub.status.idle":"2025-07-27T14:45:10.751661Z","shell.execute_reply.started":"2025-07-27T14:45:10.722737Z","shell.execute_reply":"2025-07-27T14:45:10.750700Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# since Cabin was an object, it didn't appear in the describe method,\n# but now we know it has a lot of null values\ntitanic.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:10.753271Z","iopub.execute_input":"2025-07-27T14:45:10.753784Z","iopub.status.idle":"2025-07-27T14:45:10.776844Z","shell.execute_reply.started":"2025-07-27T14:45:10.753762Z","shell.execute_reply":"2025-07-27T14:45:10.776014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# the Cabin column has 147 different unique values,\n# which makes one hot encoding inefficient\ntitanic['Cabin'].nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:10.778156Z","iopub.execute_input":"2025-07-27T14:45:10.778482Z","iopub.status.idle":"2025-07-27T14:45:10.799188Z","shell.execute_reply.started":"2025-07-27T14:45:10.778454Z","shell.execute_reply":"2025-07-27T14:45:10.798508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# the Ticket column just tells you the \n# type of ticket, as \"STON/02.\" may show.\n# ordinal encoding may be useful here\ntitanic['Ticket']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:10.800031Z","iopub.execute_input":"2025-07-27T14:45:10.800307Z","iopub.status.idle":"2025-07-27T14:45:10.822088Z","shell.execute_reply.started":"2025-07-27T14:45:10.800284Z","shell.execute_reply":"2025-07-27T14:45:10.820969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# in the data description of the competition,\n# it says there are 3 ports, \n# C = Cherbourg\n# Q = Queenstown\n# S = Southampton\n# this is perfect for one hot encoding\ntitanic['Embarked']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:10.822988Z","iopub.execute_input":"2025-07-27T14:45:10.823173Z","iopub.status.idle":"2025-07-27T14:45:10.844522Z","shell.execute_reply.started":"2025-07-27T14:45:10.823160Z","shell.execute_reply":"2025-07-27T14:45:10.843657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# I will drop this column, since it's useless\ntitanic['PassengerId']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:10.845287Z","iopub.execute_input":"2025-07-27T14:45:10.845549Z","iopub.status.idle":"2025-07-27T14:45:10.865862Z","shell.execute_reply.started":"2025-07-27T14:45:10.845523Z","shell.execute_reply":"2025-07-27T14:45:10.865122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# I will create a new feature for the amount of family members\n# family members = siblings + spouses + parents + children\ntitanic['FamMembers'] = titanic['SibSp'] + titanic['Parch']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:10.866543Z","iopub.execute_input":"2025-07-27T14:45:10.866755Z","iopub.status.idle":"2025-07-27T14:45:10.884598Z","shell.execute_reply.started":"2025-07-27T14:45:10.866737Z","shell.execute_reply":"2025-07-27T14:45:10.883734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# splitting the data into training and validation sets\nfrom sklearn.model_selection import train_test_split\n\ny = titanic['Survived']\nX = titanic.drop('Survived', axis=1)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:10.887236Z","iopub.execute_input":"2025-07-27T14:45:10.887485Z","iopub.status.idle":"2025-07-27T14:45:12.384863Z","shell.execute_reply.started":"2025-07-27T14:45:10.887466Z","shell.execute_reply":"2025-07-27T14:45:12.383774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# I drop PassengerId column\nX_train.drop('PassengerId', axis=1, inplace=True)\nX_valid.drop('PassengerId', axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:12.385894Z","iopub.execute_input":"2025-07-27T14:45:12.386364Z","iopub.status.idle":"2025-07-27T14:45:12.394036Z","shell.execute_reply.started":"2025-07-27T14:45:12.386339Z","shell.execute_reply":"2025-07-27T14:45:12.392389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# separating the data between numerical and categorical columns.\n# since the dataset doesn't have too many columns, I will keep all\nnumerical_cols = X_train.select_dtypes(include=['int64','float64']).columns\ncategorical_cols = X_train.select_dtypes(include=['object']).columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:12.395009Z","iopub.execute_input":"2025-07-27T14:45:12.395304Z","iopub.status.idle":"2025-07-27T14:45:12.419827Z","shell.execute_reply.started":"2025-07-27T14:45:12.395278Z","shell.execute_reply":"2025-07-27T14:45:12.418590Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# we obtain One Hot Encoding, Ordinal Encoding and Target Encoding columns\nohe_cols = [col for col in categorical_cols if X_train[col].nunique() <= 3]\nordinal_cols = [col for col in categorical_cols if 3 < X_train[col].nunique() < 10]\nhigh_cardinality_cols = [col for col in categorical_cols if X_train[col].nunique() >= 10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:12.420596Z","iopub.execute_input":"2025-07-27T14:45:12.420903Z","iopub.status.idle":"2025-07-27T14:45:12.444138Z","shell.execute_reply.started":"2025-07-27T14:45:12.420878Z","shell.execute_reply":"2025-07-27T14:45:12.443231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# fill null values with the median in numerical columns\nfrom sklearn.impute import SimpleImputer\n\nnum_cols_transformer = SimpleImputer(strategy='median')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:12.445200Z","iopub.execute_input":"2025-07-27T14:45:12.445517Z","iopub.status.idle":"2025-07-27T14:45:12.707676Z","shell.execute_reply.started":"2025-07-27T14:45:12.445494Z","shell.execute_reply":"2025-07-27T14:45:12.706933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pipelines for categorical columns\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom category_encoders import TargetEncoder\nfrom sklearn.pipeline import Pipeline\n\nohe_cols_transformer = Pipeline(steps=[\n    ('impute', SimpleImputer(strategy='most_frequent')),\n    ('ohe', OneHotEncoder(handle_unknown='ignore',\n                           sparse_output=False))\n])\n\nordinal_cols_transformer = Pipeline(steps=[\n    ('impute', SimpleImputer(strategy='most_frequent')),\n    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value',\n                                unknown_value=-1))\n])\n\nhigh_cardinality_cols_transformer = Pipeline(steps=[\n    ('impute', SimpleImputer(strategy='most_frequent')),\n    ('target', TargetEncoder())\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:12.708530Z","iopub.execute_input":"2025-07-27T14:45:12.708759Z","iopub.status.idle":"2025-07-27T14:45:13.401502Z","shell.execute_reply.started":"2025-07-27T14:45:12.708741Z","shell.execute_reply":"2025-07-27T14:45:13.400403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# bundle all the pipelines into a ColumnTransformer\nfrom sklearn.compose import ColumnTransformer\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', num_cols_transformer, numerical_cols),\n        ('ohe', ohe_cols_transformer, ohe_cols),\n        ('ord', ordinal_cols_transformer, ordinal_cols),\n        ('hcc', high_cardinality_cols_transformer, high_cardinality_cols)\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:45:13.402429Z","iopub.execute_input":"2025-07-27T14:45:13.402839Z","iopub.status.idle":"2025-07-27T14:45:13.423278Z","shell.execute_reply.started":"2025-07-27T14:45:13.402816Z","shell.execute_reply":"2025-07-27T14:45:13.422398Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# using AdaBoost as the model\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel = AdaBoostClassifier(\n    base_estimator = DecisionTreeClassifier(max_depth=1),\n    n_estimators = 50,\n    learning_rate = 0.05,\n    random_state = 0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:46:54.714991Z","iopub.execute_input":"2025-07-27T14:46:54.715293Z","iopub.status.idle":"2025-07-27T14:46:54.720111Z","shell.execute_reply.started":"2025-07-27T14:46:54.715272Z","shell.execute_reply":"2025-07-27T14:46:54.719092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train the model and get the predictions\nfrom sklearn.metrics import mean_squared_error\n\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\n\npipeline.fit(X_train, y_train),\npredictions = pipeline.predict(X_valid)\nscore = mean_squared_error(y_valid, predictions)\nprint(f'Score: {score}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:46:57.640513Z","iopub.execute_input":"2025-07-27T14:46:57.640868Z","iopub.status.idle":"2025-07-27T14:46:57.690782Z","shell.execute_reply.started":"2025-07-27T14:46:57.640844Z","shell.execute_reply":"2025-07-27T14:46:57.690136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# get the test predictions\ntitanic_test = pd.read_csv('/kaggle/input/titanic/test.csv')\n\ntitanic_test['FamMembers'] = titanic_test['SibSp'] + titanic_test['Parch']\nX_test = titanic_test[X_train.columns]\n\nfinal_predictions = pipeline.predict(X_test)\n\nsubmission = pd.DataFrame({\n    'PassengerId': titanic_test['PassengerId'],\n    'Survived': final_predictions\n})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T14:47:04.933112Z","iopub.execute_input":"2025-07-27T14:47:04.933357Z","iopub.status.idle":"2025-07-27T14:47:04.954539Z","shell.execute_reply.started":"2025-07-27T14:47:04.933340Z","shell.execute_reply":"2025-07-27T14:47:04.953493Z"}},"outputs":[],"execution_count":null}]}